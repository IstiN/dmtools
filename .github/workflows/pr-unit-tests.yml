name: PR Unit Tests

on:
  pull_request:
    branches: [ main, develop ]
    types: [ opened, synchronize, reopened, ready_for_review ]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
      checks: write # Required for test reporting
      pull-requests: write # Required for PR comments

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup DMTools Environment
        uses: ./.github/actions/setup-environment
        with:
          cache-key-suffix: '-unit-tests'

      - name: üßπ Clean build directories
        run: ./gradlew clean
        
      - name: üß™ core:unitTests
        id: core-tests
        continue-on-error: true
        run: |
          ./gradlew :dmtools-core:test -x integrationTest 2>&1 | tee core-test-output.log
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: üß™ server:unitTests  
        id: server-tests
        continue-on-error: true
        run: |
          ./gradlew :dmtools-server:test -x integrationTest 2>&1 | tee server-test-output.log
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: üì¶ Build core shadow JAR
        id: gradle
        continue-on-error: true
        run: |
          ./gradlew :dmtools-core:shadowJar 2>&1 | tee shadowjar-output.log
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Unit Test Report
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Unit Tests
          path: '**/build/test-results/test/TEST-*.xml'
          reporter: java-junit
          fail-on-error: false

      - name: üîç Create Detailed Failure Summary for AI Auto-Fix
        if: always()
        id: analyze-compilation
        run: |
          # Check if there are any failures before proceeding
          core_failed="${{ steps.core-tests.outcome != 'success' }}"
          server_failed="${{ steps.server-tests.outcome != 'success' }}"
          build_failed="${{ steps.gradle.outcome != 'success' }}"
          
          if [ "$core_failed" = "true" ] || [ "$server_failed" = "true" ] || [ "$build_failed" = "true" ]; then
            echo "COMPILATION_ERRORS_FOUND=false" >> $GITHUB_OUTPUT
            echo "ERROR_SUMMARY=" >> $GITHUB_OUTPUT
            echo "FAILED_FILES=" >> $GITHUB_OUTPUT
            
            # Create detailed failure summary file for AI auto-fix
            echo "# ü§ñ Detailed Test Failure Analysis for AI Auto-Fix" > failure-summary.md
            echo "" >> failure-summary.md
            echo "## Build Status Overview" >> failure-summary.md
            echo "- **core:unitTests**: ${{ steps.core-tests.outcome }}" >> failure-summary.md
            echo "- **server:unitTests**: ${{ steps.server-tests.outcome }}" >> failure-summary.md
            echo "- **shadowJar build**: ${{ steps.gradle.outcome }}" >> failure-summary.md
            echo "" >> failure-summary.md
            
            # Variables for collecting error information
            compilation_errors=""
            failed_files=""
            has_compilation_errors=false
            
            # Analyze each log file for compilation errors and detailed failure information
            for log_file in core-test-output.log server-test-output.log shadowjar-output.log; do
              if [ -f "$log_file" ]; then
                echo "### üìã Analysis of $log_file" >> failure-summary.md
                echo "" >> failure-summary.md
                
                # Check for compilation errors
                if grep -q "error:\|cannot find symbol\|package does not exist\|Compilation failed\|BUILD FAILED" "$log_file"; then
                  has_compilation_errors=true
                  echo "COMPILATION_ERRORS_FOUND=true" >> $GITHUB_OUTPUT
                  
                  echo "#### ‚ùå Compilation Errors Found" >> failure-summary.md
                  echo "" >> failure-summary.md
                  
                  # Extract detailed compilation error information
                  echo "**Detailed Error Messages:**" >> failure-summary.md
                  echo '```' >> failure-summary.md
                  grep -n -A 3 -B 1 "error:\|cannot find symbol\|package does not exist" "$log_file" | head -50 >> failure-summary.md
                  echo '```' >> failure-summary.md
                  echo "" >> failure-summary.md
                  
                  # Extract specific error file locations
                  error_files=$(grep -o '[^[:space:]]*/[^[:space:]]*\.java:[0-9]*:' "$log_file" | cut -d: -f1 | sort -u)
                  if [ -n "$error_files" ]; then
                    echo "**Files requiring fixes:**" >> failure-summary.md
                    echo "$error_files" | sed 's/^/- /' >> failure-summary.md
                    failed_files="$failed_files $error_files"
                    echo "" >> failure-summary.md
                  fi
                  
                  # Extract specific error types for categorization
                  specific_errors=$(grep -o "error: [^,]*" "$log_file" | head -10)
                  if [ -n "$specific_errors" ]; then
                    echo "**Error Types:**" >> failure-summary.md
                    echo "$specific_errors" | sed 's/^/- /' >> failure-summary.md
                    compilation_errors="$compilation_errors $specific_errors"
                    echo "" >> failure-summary.md
                  fi
                  
                  # Extract full compilation failure context
                  echo "**Complete Error Context:**" >> failure-summary.md
                  echo '```' >> failure-summary.md
                  if grep -q "BUILD FAILED" "$log_file"; then
                    # Get the build failure section with full context
                    sed -n '/BUILD FAILED/,/BUILD FAILED\|Deprecated Gradle features\|$/{p}' "$log_file" | head -100 >> failure-summary.md
                  else
                    # Get error context around compilation failures
                    grep -A 10 -B 5 "error:\|cannot find symbol\|package does not exist" "$log_file" | head -100 >> failure-summary.md
                  fi
                  echo '```' >> failure-summary.md
                  echo "" >> failure-summary.md
                else
                  echo "‚úÖ No compilation errors found in $log_file" >> failure-summary.md
                  echo "" >> failure-summary.md
                fi
              fi
            done
            
            # Set outputs for AI analysis
            if [ -n "$compilation_errors" ]; then
              echo "ERROR_SUMMARY<<EOF" >> $GITHUB_OUTPUT
              echo "$compilation_errors" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
            
            if [ -n "$failed_files" ]; then
              echo "FAILED_FILES<<EOF" >> $GITHUB_OUTPUT
              echo "$failed_files" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
            
            # Add test failure analysis from XML files if compilation succeeded
            if [ "$has_compilation_errors" = "false" ]; then
              echo "## Test Failure Analysis" >> failure-summary.md
              echo "" >> failure-summary.md
              
              failed_tests_found=false
              if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
                for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
                  if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                    failed_tests_found=true
                    echo "### Failed Test: $test_file" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    class_name=$(xmllint --xpath "string(//testsuite/@name)" "$test_file" 2>/dev/null || echo "Unknown")
                    echo "**Test Class:** $class_name" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    echo "**Failed Methods:**" >> failure-summary.md
                    xmllint --xpath "//testcase[failure or error]/@name" "$test_file" 2>/dev/null | tr ' ' '\n' | sed 's/name=//g' | sed 's/"//g' | sed 's/^/- /' >> failure-summary.md || echo "- Could not extract method names" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    echo "**Detailed Failure Messages:**" >> failure-summary.md
                    echo '```' >> failure-summary.md
                    xmllint --xpath "//failure/text() | //error/text()" "$test_file" 2>/dev/null >> failure-summary.md || echo "Could not extract failure details" >> failure-summary.md
                    echo '```' >> failure-summary.md
                    echo "" >> failure-summary.md
                  fi
                done
              fi
              
              if [ "$failed_tests_found" = "false" ]; then
                echo "No test failures found in XML files - issues may be build-related." >> failure-summary.md
                echo "" >> failure-summary.md
              fi
            fi
            
            # Add AI-specific analysis and recommendations
            echo "## ü§ñ AI Auto-Fix Instructions" >> failure-summary.md
            echo "" >> failure-summary.md
            
            if [ "$has_compilation_errors" = "true" ]; then
              echo "**Primary Issue:** Java compilation errors preventing build completion" >> failure-summary.md
              echo "**Priority:** CRITICAL - Must fix compilation errors before tests can run" >> failure-summary.md
              echo "" >> failure-summary.md
              echo "**Recommended Actions:**" >> failure-summary.md
              echo "1. Fix annotation syntax errors (especially @WebMvcTest usage)" >> failure-summary.md
              echo "2. Resolve missing imports or dependency issues" >> failure-summary.md
              echo "3. Address 'cannot find symbol' errors" >> failure-summary.md
              echo "4. Ensure proper parameter syntax in annotations" >> failure-summary.md
            elif [ "${{ steps.core-tests.outcome != 'success' }}" = "true" ] || [ "${{ steps.server-tests.outcome != 'success' }}" = "true" ]; then
              echo "**Primary Issue:** Test execution failures after successful compilation" >> failure-summary.md
              echo "**Priority:** HIGH - Fix failing unit tests" >> failure-summary.md
              echo "" >> failure-summary.md
              echo "**Recommended Actions:**" >> failure-summary.md
              echo "1. Review and fix failing test assertions" >> failure-summary.md
              echo "2. Check test configuration and setup" >> failure-summary.md
              echo "3. Verify mock configurations and test data" >> failure-summary.md
              echo "4. Ensure proper test isolation and cleanup" >> failure-summary.md
            else
              echo "**Primary Issue:** Build configuration or dependency problems" >> failure-summary.md
              echo "**Priority:** MEDIUM - Investigate build setup" >> failure-summary.md
            fi
            
            echo "" >> failure-summary.md
            echo "**Context:** This analysis was generated for PR #${{ github.event.number }} on branch ${{ github.head_ref }}" >> failure-summary.md
            echo "**Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> failure-summary.md
            
            # Also add to step summary (only summary for human readability)
            echo "## ü§ñ AI-Readable Failure Analysis" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "A detailed failure summary has been created for the AI auto-fix workflow." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quick Summary:**" >> $GITHUB_STEP_SUMMARY
            if [ "$has_compilation_errors" = "true" ]; then
              echo "- ‚ùå **Primary Issue:** Compilation errors in Java code" >> $GITHUB_STEP_SUMMARY
              echo "- üéØ **Focus:** Fix annotation syntax and compilation errors" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå **Primary Issue:** Test execution failures" >> $GITHUB_STEP_SUMMARY
              echo "- üéØ **Focus:** Fix failing unit tests and assertions" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "üìÑ **Detailed failure summary created:** \`failure-summary.md\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚úÖ All tests and build passed - no failure analysis needed" >> $GITHUB_STEP_SUMMARY
            echo "COMPILATION_ERRORS_FOUND=false" >> $GITHUB_OUTPUT
          fi

      - name: Print Failed Tests and Build Issues
        if: steps.core-tests.outcome == 'failure' || steps.server-tests.outcome == 'failure' || steps.gradle.outcome == 'failure'
        run: |
          echo "## üö® Build and Test Failure Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check which steps failed
          core_failed="${{ steps.core-tests.outcome == 'failure' }}"
          server_failed="${{ steps.server-tests.outcome == 'failure' }}"
          build_failed="${{ steps.gradle.outcome == 'failure' }}"
          
          echo "### üìã Failed Steps:" >> $GITHUB_STEP_SUMMARY
          if [ "$core_failed" = "true" ]; then
            echo "- ‚ùå **core:unitTests** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$server_failed" = "true" ]; then
            echo "- ‚ùå **server:unitTests** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$build_failed" = "true" ]; then
            echo "- ‚ùå **Build core shadow JAR** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Look for compilation errors first (these prevent test XML generation)
          if [ "$core_failed" = "true" ] || [ "$server_failed" = "true" ]; then
            echo "### üîß Compilation Issues:" >> $GITHUB_STEP_SUMMARY
            echo "If steps failed due to compilation errors, check the step logs above for:" >> $GITHUB_STEP_SUMMARY
            echo "- \`cannot find symbol\` errors" >> $GITHUB_STEP_SUMMARY
            echo "- \`package does not exist\` errors" >> $GITHUB_STEP_SUMMARY
            echo "- Import or dependency issues" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Look for actual test failures in XML files
          echo "### üß™ Unit Test Failures:" >> $GITHUB_STEP_SUMMARY
          failed_found=false
          test_file_count=0
          
          if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
            for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
              test_file_count=$((test_file_count + 1))
              if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                failed_found=true
                echo "#### Test file: $test_file" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                class_name=$(xmllint --xpath "string(//testsuite/@name)" "$test_file" 2>/dev/null || echo "Unknown")
                echo "**Class**: $class_name" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                echo "**Failed methods**:" >> $GITHUB_STEP_SUMMARY
                xmllint --xpath "//testcase[failure or error]/@name" "$test_file" 2>/dev/null | tr ' ' '\n' | sed 's/name=//g' | sed 's/"//g' | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY || echo "- Could not extract method names" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                echo "**Failure details**:" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                xmllint --xpath "//failure/text() | //error/text()" "$test_file" 2>/dev/null >> $GITHUB_STEP_SUMMARY || echo "Could not extract failure details" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          
          if [ "$failed_found" = "false" ] && [ "$test_file_count" -eq 0 ]; then
            echo "No test result XML files found - likely compilation errors prevented tests from running." >> $GITHUB_STEP_SUMMARY
          elif [ "$failed_found" = "false" ]; then
            echo "No test failures found in $test_file_count XML files - failures likely due to compilation errors." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Total test result files found**: $test_file_count" >> $GITHUB_STEP_SUMMARY

      - name: Upload Unit Test Results and Build Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-pr-${{ github.event.number }}
          path: |
            build/reports/tests/test
            build/test-results/test
            dmtools-core/build/reports/tests/test
            dmtools-core/build/test-results/test
            dmtools-server/build/reports/tests/test
            dmtools-server/build/test-results/test
            core-test-output.log
            server-test-output.log
            shadowjar-output.log
            failure-summary.md
          retention-days: 7

      - name: Comment PR with unit test results
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const coreTestsSuccess = '${{ steps.core-tests.outcome }}' === 'success';
            const serverTestsSuccess = '${{ steps.server-tests.outcome }}' === 'success';
            const shadowJarSuccess = '${{ steps.gradle.outcome }}' === 'success';
            const compilationErrorsFound = '${{ steps.analyze-compilation.outputs.COMPILATION_ERRORS_FOUND }}' === 'true';
            const errorSummary = '${{ steps.analyze-compilation.outputs.ERROR_SUMMARY }}';
            const failedFiles = '${{ steps.analyze-compilation.outputs.FAILED_FILES }}';
            
            // Overall build success requires ALL steps to pass (including compilation)
            const overallBuildSuccess = coreTestsSuccess && serverTestsSuccess && shadowJarSuccess;
            
            let comment = '## üß™ Unit Test Results\n\n';
            
            if (overallBuildSuccess) {
              comment += '‚úÖ **All unit tests passed!**\n\n';
              comment += '- ‚úÖ **core:unitTests**: PASSED\n';
              comment += '- ‚úÖ **server:unitTests**: PASSED\n';
              comment += '- ‚úÖ **Build**: PASSED\n';
            } else {
              comment += '‚ùå **Unit tests or build failed**\n\n';
              comment += `- ${coreTestsSuccess ? '‚úÖ' : '‚ùå'} **core:unitTests**: ${coreTestsSuccess ? 'PASSED' : 'FAILED'}\n`;
              comment += `- ${serverTestsSuccess ? '‚úÖ' : '‚ùå'} **server:unitTests**: ${serverTestsSuccess ? 'PASSED' : 'FAILED'}\n`;
              comment += `- ‚ùå **Build**: FAILED (compilation or build issues)\n`;
              
              // Add AI-friendly compilation error analysis
              if (compilationErrorsFound) {
                comment += '\n### ü§ñ AI Analysis: Compilation Errors Detected\n\n';
                comment += '**Primary Issue:** Java compilation failure\n';
                comment += '**Root Cause:** Code compilation errors preventing build completion\n\n';
                
                if (errorSummary) {
                  comment += '**Error Types:**\n';
                  comment += `\`\`\`\n${errorSummary}\n\`\`\`\n\n`;
                }
                
                if (failedFiles) {
                  comment += '**Files requiring fixes:**\n';
                  const files = failedFiles.split(' ').filter(f => f.trim());
                  files.forEach(file => {
                    if (file.trim()) comment += `- \`${file.trim()}\`\n`;
                  });
                  comment += '\n';
                }
                
                comment += '**Action Required:** Fix compilation errors before tests can run\n';
                comment += '**Priority:** HIGH - blocks all testing\n\n';
              } else {
                comment += '\n### ü§ñ AI Analysis: Test Execution Issues\n\n';
                comment += '**Primary Issue:** Tests failed after successful compilation\n';
                comment += '**Root Cause:** Unit test failures or build configuration issues\n';
                comment += '**Action Required:** Review test failures and fix failing tests\n\n';
              }
              
              comment += '\nüìã Check the workflow run for detailed test results and artifacts.\n';
              
              // Add specific guidance for compilation failures
              if (!coreTestsSuccess || !serverTestsSuccess) {
                comment += '\n‚ö†Ô∏è **Note**: If tests failed due to compilation errors, no test XML files will be generated.\n';
              }
            }
            
            comment += '\nüîó [View full test results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            comment += '\nüì• [Download build logs and test results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Set final status
        if: always()
        run: |
          echo "üîç Debug: Gradle step outcome = '${{ steps.gradle.outcome }}'"
          echo "üîç Debug: Gradle step conclusion = '${{ steps.gradle.conclusion }}'"
          
          echo "## üìä Unit Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check if there are any actual test failures by examining test result files
          failed_tests_found=false
          test_files_count=0
          
          if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
            for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
              test_files_count=$((test_files_count + 1))
              if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                failed_tests_found=true
                break
              fi
            done
          fi
          
          echo "üîç Debug: Test files found = $test_files_count"
          echo "üîç Debug: Failed tests found = $failed_tests_found"
          
          # Check outcomes of all test and build steps
          core_success="${{ steps.core-tests.outcome }}"
          server_success="${{ steps.server-tests.outcome }}"
          shadow_jar_success="${{ steps.gradle.outcome }}"
          
          # Overall build is successful only if ALL compilation and build steps pass
          # If core-tests or server-tests fail due to compilation, overall build failed
          overall_build_success="success"
          if [ "$core_success" != "success" ] || [ "$server_success" != "success" ] || [ "$shadow_jar_success" != "success" ]; then
            overall_build_success="failure"
          fi
          
          # Check if compilation errors were detected
          compilation_errors_found="${{ steps.analyze-compilation.outputs.COMPILATION_ERRORS_FOUND }}"
          
          if [ "$overall_build_success" = "success" ]; then
            echo "‚úÖ **All tests and build passed successfully!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ **core:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ **server:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "- ‚úÖ **Build**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The PR is ready for review." >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ All tests and build passed - workflow succeeds"
          else
            # One or more steps failed - analyze which ones
            echo "üîç Debug: Some steps failed - core: $core_success, server: $server_success, shadowJar: $shadow_jar_success"
            echo "üîç Debug: Compilation errors found: $compilation_errors_found"
            
            # Show detailed status for each step
            echo "‚ùå **Tests or build failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ "$core_success" = "success" ]; then
              echo "- ‚úÖ **core:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå **core:unitTests**: FAILED" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ "$server_success" = "success" ]; then
              echo "- ‚úÖ **server:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ùå **server:unitTests**: FAILED" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Build status should reflect overall compilation success
            echo "- ‚ùå **Build**: FAILED (due to compilation or build issues)" >> $GITHUB_STEP_SUMMARY
            
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Prioritize compilation errors as they are more fundamental
            if [ "$compilation_errors_found" = "true" ]; then
              echo "**Issue:** ‚ö†Ô∏è COMPILATION ERRORS prevent build completion" >> $GITHUB_STEP_SUMMARY
              echo "**Priority:** HIGH - Fix compilation errors first" >> $GITHUB_STEP_SUMMARY
              echo "**Next Steps:** Review the AI Analysis section above for specific error details" >> $GITHUB_STEP_SUMMARY
              echo "‚ùå Compilation errors detected - failing workflow"
              exit 1
            elif [ "$failed_tests_found" = "true" ]; then
              echo "**Issue:** Unit test failures detected in test results." >> $GITHUB_STEP_SUMMARY
              echo "Please fix the failing unit tests before merging." >> $GITHUB_STEP_SUMMARY
              echo "‚ùå Tests failed - failing workflow"
              exit 1
            else
              # Any step failure means workflow should fail
              echo "**Issue:** One or more steps failed. Check the build logs for specific details." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Common causes:**" >> $GITHUB_STEP_SUMMARY
              echo "- Compilation errors in Java code" >> $GITHUB_STEP_SUMMARY
              echo "- Unit test failures" >> $GITHUB_STEP_SUMMARY
              echo "- Missing dependencies or classpath issues" >> $GITHUB_STEP_SUMMARY
              echo "- Build configuration problems" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Please fix the issues before merging." >> $GITHUB_STEP_SUMMARY
              echo "‚ùå Steps failed - failing workflow"
              exit 1
            fi
          fi
