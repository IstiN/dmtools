name: PR Unit Tests

on:
  pull_request:
    branches: [ main, develop ]
    types: [ opened, synchronize, reopened, ready_for_review ]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
      checks: write # Required for test reporting
      pull-requests: write # Required for PR comments

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup DMTools Environment
        uses: ./.github/actions/setup-environment
        with:
          cache-key-suffix: '-unit-tests'
          install-playwright: 'false'

      - name: 🧹 Clean build directories
        run: ./gradlew clean
        
      - name: 🧪 core:unitTests
        id: core-tests
        continue-on-error: true
        run: |
          set +e  # Don't exit on error, we want to capture the exit code
          
          # Use bash PIPEFAIL to get the correct exit code when using tee
          set -o pipefail
          
          # Run gradle and capture both output and exit code properly
          ./gradlew :dmtools-core:test -x integrationTest 2>&1 | tee core-test-output.log
          EXIT_CODE=${PIPESTATUS[0]}  # Get exit code from gradle, not tee
          
          echo "CORE_EXIT_CODE=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "🔍 Debug: Gradle core test exit code = $EXIT_CODE"
          
          if [ $EXIT_CODE -ne 0 ]; then
            echo "❌ Core tests failed with exit code $EXIT_CODE"
            exit $EXIT_CODE  # This will make the step fail but continue-on-error allows workflow to continue
          else
            echo "✅ Core tests passed"
          fi
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: 🧪 server:unitTests  
        id: server-tests
        continue-on-error: true
        run: |
          set +e  # Don't exit on error, we want to capture the exit code
          
          # Use bash PIPEFAIL to get the correct exit code when using tee
          set -o pipefail
          
          # Run gradle and capture both output and exit code properly
          ./gradlew :dmtools-server:test -x integrationTest 2>&1 | tee server-test-output.log
          EXIT_CODE=${PIPESTATUS[0]}  # Get exit code from gradle, not tee
          
          echo "SERVER_EXIT_CODE=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "🔍 Debug: Gradle server test exit code = $EXIT_CODE"
          
          if [ $EXIT_CODE -ne 0 ]; then
            echo "❌ Server tests failed with exit code $EXIT_CODE"
            exit $EXIT_CODE  # This will make the step fail but continue-on-error allows workflow to continue
          else
            echo "✅ Server tests passed"
          fi
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: 📦 Build core shadow JAR
        id: gradle
        continue-on-error: true
        run: |
          set +e  # Don't exit on error, we want to capture the exit code
          
          # Use bash PIPEFAIL to get the correct exit code when using tee
          set -o pipefail
          
          # Run gradle and capture both output and exit code properly
          ./gradlew :dmtools-core:shadowJar 2>&1 | tee shadowjar-output.log
          EXIT_CODE=${PIPESTATUS[0]}  # Get exit code from gradle, not tee
          
          echo "SHADOW_JAR_EXIT_CODE=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "🔍 Debug: Gradle shadow JAR exit code = $EXIT_CODE"
          
          if [ $EXIT_CODE -ne 0 ]; then
            echo "❌ Shadow JAR build failed with exit code $EXIT_CODE"
            exit $EXIT_CODE  # This will make the step fail but continue-on-error allows workflow to continue
          else
            echo "✅ Shadow JAR build passed"
          fi
        env:
          GITHUB_USERNAME: ${{ github.actor }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Unit Test Report
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Unit Tests
          path: '**/build/test-results/test/TEST-*.xml'
          reporter: java-junit
          fail-on-error: false

      - name: 🔍 Create Detailed Failure Summary for AI Auto-Fix
        if: always()
        id: analyze-compilation
        run: |
          # Check if there are any failures before proceeding
          core_failed="${{ steps.core-tests.outcome != 'success' }}"
          server_failed="${{ steps.server-tests.outcome != 'success' }}"
          build_failed="${{ steps.gradle.outcome != 'success' }}"
          
          if [ "$core_failed" = "true" ] || [ "$server_failed" = "true" ] || [ "$build_failed" = "true" ]; then
            echo "COMPILATION_ERRORS_FOUND=false" >> $GITHUB_OUTPUT
            echo "ERROR_SUMMARY=" >> $GITHUB_OUTPUT
            echo "FAILED_FILES=" >> $GITHUB_OUTPUT
            
            # Create detailed failure summary file for AI auto-fix
            echo "# 🤖 Detailed Test Failure Analysis for AI Auto-Fix" > failure-summary.md
            echo "" >> failure-summary.md
            echo "## Build Status Overview" >> failure-summary.md
            echo "- **core:unitTests**: ${{ steps.core-tests.outcome }}" >> failure-summary.md
            echo "- **server:unitTests**: ${{ steps.server-tests.outcome }}" >> failure-summary.md
            echo "- **shadowJar build**: ${{ steps.gradle.outcome }}" >> failure-summary.md
            echo "" >> failure-summary.md
            
            # Variables for collecting error information
            compilation_errors=""
            failed_files=""
            has_compilation_errors=false
            
            # Analyze each log file for compilation errors and detailed failure information
            for log_file in core-test-output.log server-test-output.log shadowjar-output.log; do
              if [ -f "$log_file" ]; then
                echo "### 📋 Analysis of $log_file" >> failure-summary.md
                echo "" >> failure-summary.md
                
                # Check for compilation errors
                if grep -q "error:\|cannot find symbol\|package does not exist\|Compilation failed\|BUILD FAILED" "$log_file"; then
                  has_compilation_errors=true
                  echo "COMPILATION_ERRORS_FOUND=true" >> $GITHUB_OUTPUT
                  
                  echo "#### ❌ Compilation Errors Found" >> failure-summary.md
                  echo "" >> failure-summary.md
                  
                  # Extract detailed compilation error information
                  echo "**Detailed Error Messages:**" >> failure-summary.md
                  echo '```' >> failure-summary.md
                  grep -n -A 3 -B 1 "error:\|cannot find symbol\|package does not exist" "$log_file" | head -50 >> failure-summary.md
                  echo '```' >> failure-summary.md
                  echo "" >> failure-summary.md
                  
                  # Extract specific error file locations
                  error_files=$(grep -o '[^[:space:]]*/[^[:space:]]*\.java:[0-9]*:' "$log_file" | cut -d: -f1 | sort -u)
                  if [ -n "$error_files" ]; then
                    echo "**Files requiring fixes:**" >> failure-summary.md
                    echo "$error_files" | sed 's/^/- /' >> failure-summary.md
                    failed_files="$failed_files $error_files"
                    echo "" >> failure-summary.md
                  fi
                  
                  # Extract specific error types for categorization
                  specific_errors=$(grep -o "error: [^,]*" "$log_file" | head -10)
                  if [ -n "$specific_errors" ]; then
                    echo "**Error Types:**" >> failure-summary.md
                    echo "$specific_errors" | sed 's/^/- /' >> failure-summary.md
                    compilation_errors="$compilation_errors $specific_errors"
                    echo "" >> failure-summary.md
                  fi
                  
                  # Extract full compilation failure context
                  echo "**Complete Error Context:**" >> failure-summary.md
                  echo '```' >> failure-summary.md
                  if grep -q "BUILD FAILED" "$log_file"; then
                    # Get the build failure section with full context
                    sed -n '/BUILD FAILED/,/BUILD FAILED\|Deprecated Gradle features\|$/{p}' "$log_file" | head -100 >> failure-summary.md
                  else
                    # Get error context around compilation failures
                    grep -A 10 -B 5 "error:\|cannot find symbol\|package does not exist" "$log_file" | head -100 >> failure-summary.md
                  fi
                  echo '```' >> failure-summary.md
                  echo "" >> failure-summary.md
                else
                  echo "✅ No compilation errors found in $log_file" >> failure-summary.md
                  echo "" >> failure-summary.md
                fi
              fi
            done
            
            # Set outputs for AI analysis
            if [ -n "$compilation_errors" ]; then
              echo "ERROR_SUMMARY<<EOF" >> $GITHUB_OUTPUT
              echo "$compilation_errors" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
            
            if [ -n "$failed_files" ]; then
              echo "FAILED_FILES<<EOF" >> $GITHUB_OUTPUT
              echo "$failed_files" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
            
            # Add test failure analysis from XML files if compilation succeeded
            if [ "$has_compilation_errors" = "false" ]; then
              echo "## Test Failure Analysis" >> failure-summary.md
              echo "" >> failure-summary.md
              
              failed_tests_found=false
              if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
                for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
                  if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                    failed_tests_found=true
                    echo "### Failed Test: $test_file" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    class_name=$(xmllint --xpath "string(//testsuite/@name)" "$test_file" 2>/dev/null || echo "Unknown")
                    echo "**Test Class:** $class_name" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    echo "**Failed Methods:**" >> failure-summary.md
                    xmllint --xpath "//testcase[failure or error]/@name" "$test_file" 2>/dev/null | tr ' ' '\n' | sed 's/name=//g' | sed 's/"//g' | sed 's/^/- /' >> failure-summary.md || echo "- Could not extract method names" >> failure-summary.md
                    echo "" >> failure-summary.md
                    
                    echo "**Detailed Failure Messages:**" >> failure-summary.md
                    echo '```' >> failure-summary.md
                    xmllint --xpath "//failure/text() | //error/text()" "$test_file" 2>/dev/null >> failure-summary.md || echo "Could not extract failure details" >> failure-summary.md
                    echo '```' >> failure-summary.md
                    echo "" >> failure-summary.md
                  fi
                done
              fi
              
              if [ "$failed_tests_found" = "false" ]; then
                echo "No test failures found in XML files - issues may be build-related." >> failure-summary.md
                echo "" >> failure-summary.md
              fi
            fi
            
            # Add AI-specific analysis and recommendations
            echo "## 🤖 AI Auto-Fix Instructions" >> failure-summary.md
            echo "" >> failure-summary.md
            
            if [ "$has_compilation_errors" = "true" ]; then
              echo "**Primary Issue:** Java compilation errors preventing build completion" >> failure-summary.md
              echo "**Priority:** CRITICAL - Must fix compilation errors before tests can run" >> failure-summary.md
              echo "" >> failure-summary.md
              echo "**Recommended Actions:**" >> failure-summary.md
              echo "1. Fix annotation syntax errors (especially @WebMvcTest usage)" >> failure-summary.md
              echo "2. Resolve missing imports or dependency issues" >> failure-summary.md
              echo "3. Address 'cannot find symbol' errors" >> failure-summary.md
              echo "4. Ensure proper parameter syntax in annotations" >> failure-summary.md
            elif [ "${{ steps.core-tests.outcome != 'success' }}" = "true" ] || [ "${{ steps.server-tests.outcome != 'success' }}" = "true" ]; then
              echo "**Primary Issue:** Test execution failures after successful compilation" >> failure-summary.md
              echo "**Priority:** HIGH - Fix failing unit tests" >> failure-summary.md
              echo "" >> failure-summary.md
              echo "**Recommended Actions:**" >> failure-summary.md
              echo "1. Review and fix failing test assertions" >> failure-summary.md
              echo "2. Check test configuration and setup" >> failure-summary.md
              echo "3. Verify mock configurations and test data" >> failure-summary.md
              echo "4. Ensure proper test isolation and cleanup" >> failure-summary.md
            else
              echo "**Primary Issue:** Build configuration or dependency problems" >> failure-summary.md
              echo "**Priority:** MEDIUM - Investigate build setup" >> failure-summary.md
            fi
            
            echo "" >> failure-summary.md
            echo "**Context:** This analysis was generated for PR #${{ github.event.number }} on branch ${{ github.head_ref }}" >> failure-summary.md
            echo "**Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> failure-summary.md
            
            # Also add to step summary (only summary for human readability)
            echo "## 🤖 AI-Readable Failure Analysis" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "A detailed failure summary has been created for the AI auto-fix workflow." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quick Summary:**" >> $GITHUB_STEP_SUMMARY
            if [ "$has_compilation_errors" = "true" ]; then
              echo "- ❌ **Primary Issue:** Compilation errors in Java code" >> $GITHUB_STEP_SUMMARY
              echo "- 🎯 **Focus:** Fix annotation syntax and compilation errors" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ❌ **Primary Issue:** Test execution failures" >> $GITHUB_STEP_SUMMARY
              echo "- 🎯 **Focus:** Fix failing unit tests and assertions" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "📄 **Detailed failure summary created:** \`failure-summary.md\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ All tests and build passed - no failure analysis needed" >> $GITHUB_STEP_SUMMARY
            echo "COMPILATION_ERRORS_FOUND=false" >> $GITHUB_OUTPUT
          fi

      - name: Print Failed Tests and Build Issues
        if: steps.core-tests.outcome == 'failure' || steps.server-tests.outcome == 'failure' || steps.gradle.outcome == 'failure'
        run: |
          echo "## 🚨 Build and Test Failure Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check which steps failed
          core_failed="${{ steps.core-tests.outcome == 'failure' }}"
          server_failed="${{ steps.server-tests.outcome == 'failure' }}"
          build_failed="${{ steps.gradle.outcome == 'failure' }}"
          
          echo "### 📋 Failed Steps:" >> $GITHUB_STEP_SUMMARY
          if [ "$core_failed" = "true" ]; then
            echo "- ❌ **core:unitTests** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$server_failed" = "true" ]; then
            echo "- ❌ **server:unitTests** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$build_failed" = "true" ]; then
            echo "- ❌ **Build core shadow JAR** - Failed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Look for compilation errors first (these prevent test XML generation)
          if [ "$core_failed" = "true" ] || [ "$server_failed" = "true" ]; then
            echo "### 🔧 Compilation Issues:" >> $GITHUB_STEP_SUMMARY
            echo "If steps failed due to compilation errors, check the step logs above for:" >> $GITHUB_STEP_SUMMARY
            echo "- \`cannot find symbol\` errors" >> $GITHUB_STEP_SUMMARY
            echo "- \`package does not exist\` errors" >> $GITHUB_STEP_SUMMARY
            echo "- Import or dependency issues" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Look for actual test failures in XML files
          echo "### 🧪 Unit Test Failures:" >> $GITHUB_STEP_SUMMARY
          failed_found=false
          test_file_count=0
          
          if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
            for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
              test_file_count=$((test_file_count + 1))
              if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                failed_found=true
                echo "#### Test file: $test_file" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                class_name=$(xmllint --xpath "string(//testsuite/@name)" "$test_file" 2>/dev/null || echo "Unknown")
                echo "**Class**: $class_name" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                echo "**Failed methods**:" >> $GITHUB_STEP_SUMMARY
                xmllint --xpath "//testcase[failure or error]/@name" "$test_file" 2>/dev/null | tr ' ' '\n' | sed 's/name=//g' | sed 's/"//g' | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY || echo "- Could not extract method names" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                echo "**Failure details**:" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                xmllint --xpath "//failure/text() | //error/text()" "$test_file" 2>/dev/null >> $GITHUB_STEP_SUMMARY || echo "Could not extract failure details" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          
          if [ "$failed_found" = "false" ] && [ "$test_file_count" -eq 0 ]; then
            echo "No test result XML files found - likely compilation errors prevented tests from running." >> $GITHUB_STEP_SUMMARY
          elif [ "$failed_found" = "false" ]; then
            echo "No test failures found in $test_file_count XML files - failures likely due to compilation errors." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Total test result files found**: $test_file_count" >> $GITHUB_STEP_SUMMARY

      - name: Upload Unit Test Results and Build Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-pr-${{ github.event.number }}
          path: |
            build/reports/tests/test
            build/test-results/test
            dmtools-core/build/reports/tests/test
            dmtools-core/build/test-results/test
            dmtools-server/build/reports/tests/test
            dmtools-server/build/test-results/test
            core-test-output.log
            server-test-output.log
            shadowjar-output.log
            failure-summary.md
          retention-days: 7

      - name: Comment PR with unit test results
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            var coreTestsSuccess = '${{ steps.core-tests.outcome }}' === 'success';
            var serverTestsSuccess = '${{ steps.server-tests.outcome }}' === 'success';
            var shadowJarSuccess = '${{ steps.gradle.outcome }}' === 'success';
            var compilationErrorsFound = '${{ steps.analyze-compilation.outputs.COMPILATION_ERRORS_FOUND }}' === 'true';
            var errorSummary = '${{ steps.analyze-compilation.outputs.ERROR_SUMMARY }}';
            var failedFiles = '${{ steps.analyze-compilation.outputs.FAILED_FILES }}';
            
            // Check exit codes for more accurate status determination
            var coreExitCode = '${{ steps.core-tests.outputs.CORE_EXIT_CODE }}' || '0';
            var serverExitCode = '${{ steps.server-tests.outputs.SERVER_EXIT_CODE }}' || '0';
            var shadowJarExitCode = '${{ steps.gradle.outputs.SHADOW_JAR_EXIT_CODE }}' || '0';
            
            // Overall build success requires ALL steps to pass AND have exit code 0
            var overallBuildSuccess = coreTestsSuccess && serverTestsSuccess && shadowJarSuccess && 
                                       coreExitCode === '0' && serverExitCode === '0' && shadowJarExitCode === '0';
            
            var comment = '## Unit Test Results\n\n';
            
            if (overallBuildSuccess) {
              comment += '**All unit tests passed!**\n\n';
              comment += '- **core:unitTests**: PASSED\n';
              comment += '- **server:unitTests**: PASSED\n';
              comment += '- **Build**: PASSED\n';
            } else {
              comment += '**Unit tests or build failed**\n\n';
              
              // More detailed status with exit codes
              var coreActuallyPassed = coreTestsSuccess && coreExitCode === '0';
              var serverActuallyPassed = serverTestsSuccess && serverExitCode === '0';
              var shadowJarActuallyPassed = shadowJarSuccess && shadowJarExitCode === '0';
              
              comment += '- ' + (coreActuallyPassed ? '[PASS]' : '[FAIL]') + ' **core:unitTests**: ' + (coreActuallyPassed ? 'PASSED' : 'FAILED (exit: ' + coreExitCode + ')') + '\n';
              comment += '- ' + (serverActuallyPassed ? '[PASS]' : '[FAIL]') + ' **server:unitTests**: ' + (serverActuallyPassed ? 'PASSED' : 'FAILED (exit: ' + serverExitCode + ')') + '\n';
              comment += '- ' + (shadowJarActuallyPassed ? '[PASS]' : '[FAIL]') + ' **shadowJar build**: ' + (shadowJarActuallyPassed ? 'PASSED' : 'FAILED (exit: ' + shadowJarExitCode + ')') + '\n';
              
              // Add debug information
              comment += '\n<details><summary>Debug Information</summary>\n\n';
              comment += '**Step Outcomes:**\n';
              comment += '- core-tests outcome: ' + (coreTestsSuccess ? 'success' : '${{ steps.core-tests.outcome }}') + '\n';
              comment += '- server-tests outcome: ' + (serverTestsSuccess ? 'success' : '${{ steps.server-tests.outcome }}') + '\n';
              comment += '- gradle outcome: ' + (shadowJarSuccess ? 'success' : '${{ steps.gradle.outcome }}') + '\n';
              comment += '\n**Exit Codes:**\n';
              comment += '- core-tests exit code: ' + coreExitCode + '\n';
              comment += '- server-tests exit code: ' + serverExitCode + '\n';
              comment += '- shadowJar exit code: ' + shadowJarExitCode + '\n';
              comment += '\n</details>\n';
              
              // Add AI-friendly compilation error analysis
              if (compilationErrorsFound) {
                comment += '\n### AI Analysis: Compilation Errors Detected\n\n';
                comment += '**Primary Issue:** Java compilation failure\n';
                comment += '**Root Cause:** Code compilation errors preventing build completion\n\n';
                
                if (errorSummary) {
                  comment += '**Error Types:**\n';
                  comment += '```\n' + errorSummary + '\n```\n\n';
                }
                
                if (failedFiles) {
                  comment += '**Files requiring fixes:**\n';
                  var files = failedFiles.split(' ').filter(function(f) { return f.trim(); });
                  for (var i = 0; i < files.length; i++) {
                    var file = files[i];
                    if (file.trim()) comment += '- `' + file.trim() + '`\n';
                  }
                  comment += '\n';
                }
                
                comment += '**Action Required:** Fix compilation errors before tests can run\n';
                comment += '**Priority:** HIGH - blocks all testing\n\n';
              } else {
                comment += '\n### AI Analysis: Test Execution Issues\n\n';
                comment += '**Primary Issue:** Tests failed after successful compilation\n';
                comment += '**Root Cause:** Unit test failures or build configuration issues\n';
                comment += '**Action Required:** Review test failures and fix failing tests\n\n';
              }
              
              comment += '\nCheck the workflow run for detailed test results and artifacts.\n';
              
              // Add specific guidance for compilation failures
              if (!coreTestsSuccess || !serverTestsSuccess) {
                comment += '\n**Note**: If tests failed due to compilation errors, no test XML files will be generated.\n';
              }
            }
            
            comment += '\n[View full test results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            comment += '\n[Download build logs and test results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Set final status
        if: always()
        run: |
          echo "🔍 Debug: Gradle step outcome = '${{ steps.gradle.outcome }}'"
          echo "🔍 Debug: Gradle step conclusion = '${{ steps.gradle.conclusion }}'"
          
          echo "## 📊 Unit Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check if there are any actual test failures by examining test result files
          failed_tests_found=false
          test_files_count=0
          
          if find . -path "*/build/test-results/test/TEST-*.xml" -type f | head -1 | read -r first_file; then
            for test_file in $(find . -path "*/build/test-results/test/TEST-*.xml" -type f); do
              test_files_count=$((test_files_count + 1))
              if grep -q 'failures="[1-9]' "$test_file" || grep -q 'errors="[1-9]' "$test_file"; then
                failed_tests_found=true
                break
              fi
            done
          fi
          
          echo "🔍 Debug: Test files found = $test_files_count"
          echo "🔍 Debug: Failed tests found = $failed_tests_found"
          
          # Check outcomes and exit codes of all test and build steps
          core_success="${{ steps.core-tests.outcome }}"
          server_success="${{ steps.server-tests.outcome }}"
          shadow_jar_success="${{ steps.gradle.outcome }}"
          
          # Also check the actual exit codes from gradle commands
          core_exit_code="${{ steps.core-tests.outputs.CORE_EXIT_CODE }}"
          server_exit_code="${{ steps.server-tests.outputs.SERVER_EXIT_CODE }}"
          shadow_jar_exit_code="${{ steps.gradle.outputs.SHADOW_JAR_EXIT_CODE }}"
          
          # Handle empty exit codes (default to 0)
          core_exit_code="${core_exit_code:-0}"
          server_exit_code="${server_exit_code:-0}"
          shadow_jar_exit_code="${shadow_jar_exit_code:-0}"
          
          echo "🔍 Debug: Exit codes - core: $core_exit_code, server: $server_exit_code, shadowJar: $shadow_jar_exit_code"
          echo "🔍 Debug: Step outcomes - core: $core_success, server: $server_success, shadowJar: $shadow_jar_success"
          
          # Overall build is successful only if ALL steps pass AND have exit code 0
          overall_build_success="success"
          if [ "$core_success" != "success" ] || [ "$server_success" != "success" ] || [ "$shadow_jar_success" != "success" ] || 
             [ "$core_exit_code" != "0" ] || [ "$server_exit_code" != "0" ] || [ "$shadow_jar_exit_code" != "0" ]; then
            overall_build_success="failure"
          fi
          
          # Check if compilation errors were detected
          compilation_errors_found="${{ steps.analyze-compilation.outputs.COMPILATION_ERRORS_FOUND }}"
          
          if [ "$overall_build_success" = "success" ]; then
            echo "✅ **All tests and build passed successfully!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **core:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **server:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **Build**: PASSED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The PR is ready for review." >> $GITHUB_STEP_SUMMARY
            echo "✅ All tests and build passed - workflow succeeds"
          else
            # One or more steps failed - analyze which ones
            echo "🔍 Debug: Build failed - step outcomes: core=$core_success, server=$server_success, shadowJar=$shadow_jar_success"
            echo "🔍 Debug: Exit codes: core=$core_exit_code, server=$server_exit_code, shadowJar=$shadow_jar_exit_code"
            echo "🔍 Debug: Compilation errors found: $compilation_errors_found"
            
            # Show detailed status for each step
            echo "❌ **Tests or build failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Core tests status
            if [ "$core_success" = "success" ] && [ "$core_exit_code" = "0" ]; then
              echo "- ✅ **core:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ❌ **core:unitTests**: FAILED (outcome: $core_success, exit code: $core_exit_code)" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Server tests status
            if [ "$server_success" = "success" ] && [ "$server_exit_code" = "0" ]; then
              echo "- ✅ **server:unitTests**: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ❌ **server:unitTests**: FAILED (outcome: $server_success, exit code: $server_exit_code)" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Shadow JAR build status  
            if [ "$shadow_jar_success" = "success" ] && [ "$shadow_jar_exit_code" = "0" ]; then
              echo "- ✅ **shadowJar build**: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ❌ **shadowJar build**: FAILED (outcome: $shadow_jar_success, exit code: $shadow_jar_exit_code)" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Prioritize compilation errors as they are more fundamental
            if [ "$compilation_errors_found" = "true" ]; then
              echo "**Issue:** ⚠️ COMPILATION ERRORS prevent build completion" >> $GITHUB_STEP_SUMMARY
              echo "**Priority:** HIGH - Fix compilation errors first" >> $GITHUB_STEP_SUMMARY
              echo "**Next Steps:** Review the AI Analysis section above for specific error details" >> $GITHUB_STEP_SUMMARY
              echo "❌ Compilation errors detected - failing workflow"
              exit 1
            elif [ "$failed_tests_found" = "true" ]; then
              echo "**Issue:** Unit test failures detected in test results." >> $GITHUB_STEP_SUMMARY
              echo "Please fix the failing unit tests before merging." >> $GITHUB_STEP_SUMMARY
              echo "❌ Tests failed - failing workflow"
              exit 1
            else
              # Any step failure means workflow should fail
              echo "**Issue:** One or more steps failed. Check the build logs for specific details." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Common causes:**" >> $GITHUB_STEP_SUMMARY
              echo "- Compilation errors in Java code" >> $GITHUB_STEP_SUMMARY
              echo "- Unit test failures" >> $GITHUB_STEP_SUMMARY
              echo "- Missing dependencies or classpath issues" >> $GITHUB_STEP_SUMMARY
              echo "- Build configuration problems" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Please fix the issues before merging." >> $GITHUB_STEP_SUMMARY
              echo "❌ Steps failed - failing workflow"
              exit 1
            fi
          fi
